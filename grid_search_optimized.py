"""
HMM íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ (ìµœì í™” + ë³‘ë ¬í™” ë²„ì „)
ë°ì´í„° ë¡œë”© ìºì‹±ìœ¼ë¡œ 12ë°° ì†ë„ í–¥ìƒ
"""
import numpy as np
import pandas as pd
import sys
from pathlib import Path
from datetime import datetime
import logging
from typing import List, Dict, Tuple
from joblib import Parallel, delayed
import json

# ë¡œì»¬ ëª¨ë“ˆ
sys.path.insert(0, str(Path(__file__).parent / "src"))
from data_loader import ADFADataLoader
from hmm_model import AnomalyDetectorHMM
from evaluator import AnomalyDetectionEvaluator
from config import ExperimentConfig

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def prepare_data_for_window_size(window_size: int, data_dir: str,
                                  train_ratio: float = 0.6,
                                  val_ratio: float = 0.2,
                                  test_ratio: float = 0.2,
                                  random_seed: int = 42) -> Dict:
    """
    íŠ¹ì • window_sizeì— ëŒ€í•œ ë°ì´í„° ì¤€ë¹„ (ìºì‹±ìš©)

    Args:
        window_size: ìœˆë„ìš° í¬ê¸°
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
        train_ratio, val_ratio, test_ratio: ë°ì´í„° ë¶„í•  ë¹„ìœ¨
        random_seed: ëœë¤ ì‹œë“œ

    Returns:
        ì¤€ë¹„ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"Preparing data for window_size={window_size}")
    logger.info(f"{'='*80}")

    # ë°ì´í„° ë¡œë”
    data_loader = ADFADataLoader(
        data_dir=data_dir,
        window_size=window_size
    )

    # ë°ì´í„° ë¡œë“œ
    normal_sequences = data_loader.load_normal_data(data_loader.train_dir)
    attack_data = data_loader.load_attack_data()

    # ë°ì´í„° ë¶„í• 
    train_seqs, val_seqs, test_normal_seqs = data_loader.split_data(
        normal_sequences,
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        test_ratio=test_ratio,
        random_seed=random_seed
    )

    # ì‹œìŠ¤í…œ í˜¸ì¶œ ë§¤í•‘
    syscall_mapping = data_loader.get_syscall_mapping(train_seqs)
    n_observations = len(syscall_mapping)

    # ë§¤í•‘ ì ìš©
    train_seqs = data_loader.apply_mapping(train_seqs, syscall_mapping)
    val_seqs = data_loader.apply_mapping(val_seqs, syscall_mapping)
    test_normal_seqs = data_loader.apply_mapping(test_normal_seqs, syscall_mapping)

    for attack_type in attack_data.keys():
        attack_data[attack_type] = data_loader.apply_mapping(
            attack_data[attack_type], syscall_mapping
        )

    logger.info(f"âœ“ Data prepared: {len(train_seqs)} train, {len(val_seqs)} val, "
                f"{len(test_normal_seqs)} test, {n_observations} syscalls")

    return {
        'window_size': window_size,
        'train_seqs': train_seqs,
        'val_seqs': val_seqs,
        'test_normal_seqs': test_normal_seqs,
        'attack_data': attack_data,
        'n_observations': n_observations
    }


def run_single_experiment_cached(n_states: int, threshold_percentile: float,
                                  cached_data: Dict, random_seed: int = 42) -> Dict:
    """
    ìºì‹±ëœ ë°ì´í„°ë¡œ ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰

    Args:
        n_states: Hidden states ê°œìˆ˜
        threshold_percentile: Threshold percentile
        cached_data: ìºì‹±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        random_seed: ëœë¤ ì‹œë“œ

    Returns:
        ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ìºì‹±ëœ ë°ì´í„° ì¶”ì¶œ
        window_size = cached_data['window_size']
        train_seqs = cached_data['train_seqs']
        val_seqs = cached_data['val_seqs']
        test_normal_seqs = cached_data['test_normal_seqs']
        attack_data = cached_data['attack_data']
        n_observations = cached_data['n_observations']

        # HMM í•™ìŠµ
        detector = AnomalyDetectorHMM(
            n_states=n_states,
            n_observations=n_observations,
            random_state=random_seed
        )
        detector.fit(train_seqs)

        # Threshold ì„¤ì •
        detector.set_threshold_percentile(val_seqs, percentile=threshold_percentile)

        # í‰ê°€
        test_normal_preds, _ = detector.predict_with_scores(test_normal_seqs)

        all_attack_preds = []
        attack_predictions = {}

        for attack_type, sequences in attack_data.items():
            preds, _ = detector.predict_with_scores(sequences)
            attack_predictions[attack_type] = preds
            all_attack_preds.extend(preds)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        y_true = np.concatenate([
            np.zeros(len(test_normal_preds)),
            np.ones(len(all_attack_preds))
        ])

        y_pred = np.concatenate([
            test_normal_preds,
            np.array(all_attack_preds)
        ])

        evaluator = AnomalyDetectionEvaluator()
        metrics = evaluator.compute_metrics(y_true, y_pred)
        attack_detection_rates = evaluator.evaluate_attack_types(attack_data, attack_predictions)

        # ê³µê²© ìœ í˜•ë³„ íƒì§€ìœ¨ ì¶”ê°€
        for attack_type, rate in attack_detection_rates.items():
            metrics[f'DR_{attack_type}'] = rate

        # íŒŒë¼ë¯¸í„° ì¶”ê°€
        metrics['window_size'] = window_size
        metrics['n_states'] = n_states
        metrics['threshold_percentile'] = threshold_percentile

        return metrics

    except Exception as e:
        logger.error(f"Experiment failed: {str(e)}")
        return {
            'window_size': window_size,
            'n_states': n_states,
            'threshold_percentile': threshold_percentile,
            'error': str(e)
        }


class OptimizedGridSearchHMM:
    """ìµœì í™”ëœ HMM íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜"""

    def __init__(self, data_dir: str = 'adfa-ld/ADFA-LD', n_jobs: int = -1):
        """
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
            n_jobs: ë³‘ë ¬ ì‘ì—… ìˆ˜ (-1: ëª¨ë“  ì½”ì–´ ì‚¬ìš©)
        """
        self.data_dir = data_dir
        self.n_jobs = n_jobs
        self.results = []

    def run_grid_search(self, param_grid: Dict[str, List]) -> pd.DataFrame:
        """
        ìµœì í™”ëœ ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰

        Args:
            param_grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ

        Returns:
            ê²°ê³¼ DataFrame
        """
        logger.info("=" * 80)
        logger.info("OPTIMIZED Grid Search (Data Caching + Parallel)")
        logger.info("=" * 80)
        logger.info(f"\nParameter Grid:")
        for param, values in param_grid.items():
            logger.info(f"  {param}: {values}")

        window_sizes = param_grid['window_size']
        n_states_list = param_grid['n_states']
        threshold_percentiles = param_grid['threshold_percentile']

        total_experiments = len(window_sizes) * len(n_states_list) * len(threshold_percentiles)
        logger.info(f"\nTotal experiments: {total_experiments}")
        logger.info(f"Data loading: {len(window_sizes)} times (instead of {total_experiments})")
        logger.info(f"Speedup: {total_experiments / len(window_sizes):.1f}x faster data loading!")
        logger.info(f"Parallel jobs: {self.n_jobs if self.n_jobs > 0 else 'ALL CORES'}")

        # Step 1: ê° window_sizeë³„ë¡œ ë°ì´í„° ì¤€ë¹„ (ìºì‹±)
        logger.info("\n" + "=" * 80)
        logger.info("STEP 1: Preparing & Caching Data")
        logger.info("=" * 80)

        cached_datasets = {}
        for window_size in window_sizes:
            cached_datasets[window_size] = prepare_data_for_window_size(
                window_size=window_size,
                data_dir=self.data_dir,
                train_ratio=param_grid.get('train_ratio', [0.6])[0] if isinstance(param_grid.get('train_ratio', 0.6), list) else 0.6,
                val_ratio=param_grid.get('val_ratio', [0.2])[0] if isinstance(param_grid.get('val_ratio', 0.2), list) else 0.2,
                test_ratio=param_grid.get('test_ratio', [0.2])[0] if isinstance(param_grid.get('test_ratio', 0.2), list) else 0.2,
                random_seed=param_grid.get('random_seed', [42])[0] if isinstance(param_grid.get('random_seed', 42), list) else 42
            )

        # Step 2: ë³‘ë ¬ ì‹¤í—˜ ì‹¤í–‰
        logger.info("\n" + "=" * 80)
        logger.info("STEP 2: Running Experiments (Parallel)")
        logger.info("=" * 80)

        # ì‹¤í—˜ ì¡°í•© ìƒì„±
        experiment_params = []
        for window_size in window_sizes:
            for n_states in n_states_list:
                for threshold in threshold_percentiles:
                    experiment_params.append({
                        'window_size': window_size,
                        'n_states': n_states,
                        'threshold_percentile': threshold
                    })

        # ë³‘ë ¬ ì‹¤í–‰
        results_list = Parallel(n_jobs=self.n_jobs, verbose=10)(
            delayed(run_single_experiment_cached)(
                n_states=params['n_states'],
                threshold_percentile=params['threshold_percentile'],
                cached_data=cached_datasets[params['window_size']],
                random_seed=param_grid.get('random_seed', [42])[0] if isinstance(param_grid.get('random_seed', 42), list) else 42
            )
            for params in experiment_params
        )

        # ê²°ê³¼ ì €ì¥
        self.results = results_list
        results_df = pd.DataFrame(self.results)

        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"results/grid_search_optimized_{timestamp}.csv"
        results_df.to_csv(results_file, index=False)
        logger.info(f"\n\nâœ“ Grid search results saved to: {results_file}")

        return results_df

    def get_best_params(self, results_df: pd.DataFrame,
                        metric: str = 'F1',
                        fpr_constraint: float = 0.05) -> Tuple[Dict, float]:
        """ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°"""
        # ì—ëŸ¬ ê²°ê³¼ ì œê±°
        if 'error' in results_df.columns:
            results_df = results_df[results_df['error'].isna()]

        # FPR ì œì•½ ì¡°ê±´ ì ìš©
        valid_results = results_df[results_df['FPR'] <= fpr_constraint]

        if len(valid_results) == 0:
            logger.warning(f"No results satisfy FPR <= {fpr_constraint}. Using all results.")
            valid_results = results_df

        # ìµœì  ë©”íŠ¸ë¦­ ì°¾ê¸°
        best_idx = valid_results[metric].idxmax()
        best_row = valid_results.loc[best_idx]

        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        param_cols = ['window_size', 'n_states', 'threshold_percentile']
        best_params = {col: best_row[col] for col in param_cols if col in best_row}
        best_metric = best_row[metric]

        return best_params, best_metric

    def plot_results(self, results_df: pd.DataFrame, save_path: str = None):
        """ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì‹œê°í™”"""
        import matplotlib.pyplot as plt
        import seaborn as sns

        # ì—ëŸ¬ ê²°ê³¼ ì œê±°
        if 'error' in results_df.columns:
            results_df = results_df[results_df['error'].isna()]

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Optimized Grid Search Results', fontsize=16, fontweight='bold')

        # 1. FPR vs TPR
        ax = axes[0, 0]
        for n_states in sorted(results_df['n_states'].unique()):
            subset = results_df[results_df['n_states'] == n_states]
            ax.scatter(subset['FPR'], subset['TPR'],
                      label=f'states={n_states}', alpha=0.7, s=100)
        ax.axvline(x=0.05, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Target FPR=5%')
        ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Positive Rate (Detection Rate)', fontsize=12, fontweight='bold')
        ax.set_title('ROC: FPR vs TPR', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)

        # 2. F1-Score vs Window Size
        ax = axes[0, 1]
        for threshold in sorted(results_df['threshold_percentile'].unique()):
            subset = results_df[results_df['threshold_percentile'] == threshold]
            grouped = subset.groupby('window_size')['F1'].mean()
            ax.plot(grouped.index, grouped.values, marker='o',
                   label=f'threshold={threshold}%', linewidth=2, markersize=8)
        ax.set_xlabel('Window Size', fontsize=12, fontweight='bold')
        ax.set_ylabel('F1-Score', fontsize=12, fontweight='bold')
        ax.set_title('F1-Score vs Window Size', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)

        # 3. Heatmap
        ax = axes[1, 0]
        pivot_data = results_df.pivot_table(
            values='F1',
            index='n_states',
            columns='threshold_percentile',
            aggfunc='mean'
        )
        sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax,
                    vmin=0, vmax=1, cbar_kws={'label': 'F1-Score'})
        ax.set_title('F1-Score Heatmap', fontsize=14, fontweight='bold')
        ax.set_xlabel('Threshold Percentile (%)', fontsize=12)
        ax.set_ylabel('Hidden States', fontsize=12)

        # 4. Best Configuration
        ax = axes[1, 1]
        best_params, _ = self.get_best_params(results_df, metric='F1')
        best_result = results_df[
            (results_df['window_size'] == best_params['window_size']) &
            (results_df['n_states'] == best_params['n_states']) &
            (results_df['threshold_percentile'] == best_params['threshold_percentile'])
        ].iloc[0]

        metrics = ['FPR', 'TPR', 'Precision', 'Recall', 'F1', 'Accuracy']
        values = [best_result[m] * 100 for m in metrics]
        colors = ['#ff4444' if m == 'FPR' else '#44ff44' for m in metrics]

        bars = ax.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)
        ax.axhline(y=5, color='red', linestyle='--', linewidth=2, alpha=0.5, label='FPR Target')
        ax.axhline(y=90, color='green', linestyle='--', linewidth=2, alpha=0.5, label='High Performance')

        for bar, value in zip(bars, values):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,
                   f'{value:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')

        ax.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')
        ax.set_title(f'Best Model Metrics\n{best_params}', fontsize=14, fontweight='bold')
        ax.set_ylim(0, 105)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"âœ“ Plot saved to: {save_path}")

        plt.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("=" * 80)
    logger.info("OPTIMIZED HMM Grid Search")
    logger.info("Data Caching + Parallel Processing")
    logger.info("=" * 80)

    # ê·¸ë¦¬ë“œ ì„œì¹˜ ì„¤ì •
    param_grid = {
        'window_size': [300, 500, 700],
        'n_states': [10, 15, 20],
        'threshold_percentile': [5.0, 10.0, 15.0, 20.0]
    }

    # ìµœì í™”ëœ ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
    searcher = OptimizedGridSearchHMM(data_dir='adfa-ld/ADFA-LD', n_jobs=-1)
    results_df = searcher.run_grid_search(param_grid)

    # ê²°ê³¼ ë¶„ì„
    logger.info("\n" + "=" * 80)
    logger.info("RESULTS SUMMARY")
    logger.info("=" * 80)

    # í†µê³„ ìš”ì•½
    logger.info("\nMetrics Statistics:")
    logger.info(results_df[['FPR', 'TPR', 'F1', 'Accuracy']].describe())

    # ìµœì  íŒŒë¼ë¯¸í„° (FPR <= 5% ì œì•½)
    best_params_f1, best_f1 = searcher.get_best_params(results_df, metric='F1', fpr_constraint=0.05)
    logger.info(f"\nğŸ† Best Parameters (F1-Score, FPR<=5%):")
    logger.info(f"  {best_params_f1}")
    logger.info(f"  F1-Score: {best_f1:.4f}")

    # ìµœì  íŒŒë¼ë¯¸í„° (TPR ê¸°ì¤€)
    best_params_tpr, best_tpr = searcher.get_best_params(results_df, metric='TPR', fpr_constraint=0.05)
    logger.info(f"\nğŸ¯ Best Parameters (TPR/Detection Rate, FPR<=5%):")
    logger.info(f"  {best_params_tpr}")
    logger.info(f"  TPR: {best_tpr:.4f}")

    # ì‹œê°í™”
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_path = f"results/grid_search_optimized_{timestamp}.png"
    searcher.plot_results(results_df, save_path=plot_path)

    logger.info("\n" + "=" * 80)
    logger.info("âœ“ Grid Search Completed Successfully!")
    logger.info("=" * 80)


if __name__ == "__main__":
    main()
